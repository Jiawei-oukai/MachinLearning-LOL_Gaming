{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENVIORNMENT SETTING\n",
    "import os #paths to file\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "import warnings# warning filter\n",
    "\n",
    "#ploting libraries\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "#relevant ML libraries\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "#ML models\n",
    "# from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#default theme\n",
    "sns.set(context='notebook', style='darkgrid', palette='deep', font='sans-serif', font_scale=1, color_codes=False, rc=None)\n",
    "\n",
    "#warning hadle\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top_counterScore</th>\n",
       "      <th>Jug_counterScore</th>\n",
       "      <th>Mid_counterScore</th>\n",
       "      <th>Bot_counterScore</th>\n",
       "      <th>Uti_counterScore</th>\n",
       "      <th>diff_TeamAttackScore</th>\n",
       "      <th>diff_TeamDefenseScore</th>\n",
       "      <th>diff_TeamWinRate</th>\n",
       "      <th>diff_TeamComboCount</th>\n",
       "      <th>diff_TeamControlScore</th>\n",
       "      <th>diff_TeamGoldAbility</th>\n",
       "      <th>Team1_AttackDefenseBalanceScore</th>\n",
       "      <th>Team2_AttackDefenseBalanceScore</th>\n",
       "      <th>TeamVictory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-569.769231</td>\n",
       "      <td>-8.500000</td>\n",
       "      <td>-1597.315789</td>\n",
       "      <td>-1921.459091</td>\n",
       "      <td>1425.714286</td>\n",
       "      <td>-26.728</td>\n",
       "      <td>-85.524</td>\n",
       "      <td>-2.474</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.42042</td>\n",
       "      <td>-7.73310</td>\n",
       "      <td>-170.620</td>\n",
       "      <td>-229.416</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-662.225806</td>\n",
       "      <td>-1107.869565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-58.440000</td>\n",
       "      <td>-139.457143</td>\n",
       "      <td>10.102</td>\n",
       "      <td>0.622</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.12484</td>\n",
       "      <td>15.63772</td>\n",
       "      <td>-168.976</td>\n",
       "      <td>-178.456</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-714.315789</td>\n",
       "      <td>-423.875000</td>\n",
       "      <td>-472.241379</td>\n",
       "      <td>-1921.459091</td>\n",
       "      <td>-464.000000</td>\n",
       "      <td>0.534</td>\n",
       "      <td>35.238</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.20374</td>\n",
       "      <td>-19.39942</td>\n",
       "      <td>-202.664</td>\n",
       "      <td>-167.960</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-455.454545</td>\n",
       "      <td>-472.074074</td>\n",
       "      <td>608.932432</td>\n",
       "      <td>-2338.644444</td>\n",
       "      <td>410.300000</td>\n",
       "      <td>-31.714</td>\n",
       "      <td>-62.086</td>\n",
       "      <td>-5.316</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.08240</td>\n",
       "      <td>-19.05364</td>\n",
       "      <td>-153.022</td>\n",
       "      <td>-183.394</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>640.684211</td>\n",
       "      <td>-1075.000000</td>\n",
       "      <td>-420.983607</td>\n",
       "      <td>-597.052830</td>\n",
       "      <td>-301.200000</td>\n",
       "      <td>-26.140</td>\n",
       "      <td>71.988</td>\n",
       "      <td>-3.258</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.34540</td>\n",
       "      <td>-12.18616</td>\n",
       "      <td>-263.154</td>\n",
       "      <td>-165.026</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9845</th>\n",
       "      <td>-370.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1099.854167</td>\n",
       "      <td>367.823529</td>\n",
       "      <td>25.160</td>\n",
       "      <td>36.706</td>\n",
       "      <td>4.946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.03392</td>\n",
       "      <td>8.65492</td>\n",
       "      <td>-167.274</td>\n",
       "      <td>-155.728</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9846</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-154.949495</td>\n",
       "      <td>1621.933333</td>\n",
       "      <td>860.736842</td>\n",
       "      <td>1960.100000</td>\n",
       "      <td>44.122</td>\n",
       "      <td>-33.904</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.00696</td>\n",
       "      <td>4.57870</td>\n",
       "      <td>-124.410</td>\n",
       "      <td>-202.436</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9847</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>138.190476</td>\n",
       "      <td>-207.529412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1324.254717</td>\n",
       "      <td>37.680</td>\n",
       "      <td>50.148</td>\n",
       "      <td>1.768</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.25906</td>\n",
       "      <td>-6.72176</td>\n",
       "      <td>-191.892</td>\n",
       "      <td>-179.424</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9848</th>\n",
       "      <td>-311.636364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-83.076923</td>\n",
       "      <td>135.727891</td>\n",
       "      <td>14.396</td>\n",
       "      <td>-68.370</td>\n",
       "      <td>-5.622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.17414</td>\n",
       "      <td>-10.93540</td>\n",
       "      <td>-148.212</td>\n",
       "      <td>-230.978</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9849</th>\n",
       "      <td>-569.769231</td>\n",
       "      <td>-1184.600000</td>\n",
       "      <td>-530.181818</td>\n",
       "      <td>-1611.428571</td>\n",
       "      <td>-301.666667</td>\n",
       "      <td>-7.800</td>\n",
       "      <td>-145.658</td>\n",
       "      <td>-2.710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08910</td>\n",
       "      <td>-21.28426</td>\n",
       "      <td>-66.004</td>\n",
       "      <td>-203.862</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9850 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Top_counterScore  Jug_counterScore  Mid_counterScore  Bot_counterScore  \\\n",
       "0          -569.769231         -8.500000      -1597.315789      -1921.459091   \n",
       "1          -662.225806      -1107.869565          0.000000        -58.440000   \n",
       "2          -714.315789       -423.875000       -472.241379      -1921.459091   \n",
       "3          -455.454545       -472.074074        608.932432      -2338.644444   \n",
       "4           640.684211      -1075.000000       -420.983607       -597.052830   \n",
       "...                ...               ...               ...               ...   \n",
       "9845       -370.222222          0.000000          0.000000       1099.854167   \n",
       "9846          0.000000       -154.949495       1621.933333        860.736842   \n",
       "9847          0.000000        138.190476       -207.529412          0.000000   \n",
       "9848       -311.636364          0.000000          0.000000        -83.076923   \n",
       "9849       -569.769231      -1184.600000       -530.181818      -1611.428571   \n",
       "\n",
       "      Uti_counterScore  diff_TeamAttackScore  diff_TeamDefenseScore  \\\n",
       "0          1425.714286               -26.728                -85.524   \n",
       "1          -139.457143                10.102                  0.622   \n",
       "2          -464.000000                 0.534                 35.238   \n",
       "3           410.300000               -31.714                -62.086   \n",
       "4          -301.200000               -26.140                 71.988   \n",
       "...                ...                   ...                    ...   \n",
       "9845        367.823529                25.160                 36.706   \n",
       "9846       1960.100000                44.122                -33.904   \n",
       "9847      -1324.254717                37.680                 50.148   \n",
       "9848        135.727891                14.396                -68.370   \n",
       "9849       -301.666667                -7.800               -145.658   \n",
       "\n",
       "      diff_TeamWinRate  diff_TeamComboCount  diff_TeamControlScore  \\\n",
       "0               -2.474                 -1.0               -0.42042   \n",
       "1               -0.086                  0.0               -0.12484   \n",
       "2                0.138                  0.0               -0.20374   \n",
       "3               -5.316                 -1.0               -0.08240   \n",
       "4               -3.258                  1.0                0.34540   \n",
       "...                ...                  ...                    ...   \n",
       "9845             4.946                  0.0               -0.03392   \n",
       "9846             0.094                  0.0               -0.00696   \n",
       "9847             1.768                 -1.0                0.25906   \n",
       "9848            -5.622                  0.0               -0.17414   \n",
       "9849            -2.710                  0.0                0.08910   \n",
       "\n",
       "      diff_TeamGoldAbility  Team1_AttackDefenseBalanceScore  \\\n",
       "0                 -7.73310                         -170.620   \n",
       "1                 15.63772                         -168.976   \n",
       "2                -19.39942                         -202.664   \n",
       "3                -19.05364                         -153.022   \n",
       "4                -12.18616                         -263.154   \n",
       "...                    ...                              ...   \n",
       "9845               8.65492                         -167.274   \n",
       "9846               4.57870                         -124.410   \n",
       "9847              -6.72176                         -191.892   \n",
       "9848             -10.93540                         -148.212   \n",
       "9849             -21.28426                          -66.004   \n",
       "\n",
       "      Team2_AttackDefenseBalanceScore  TeamVictory  \n",
       "0                            -229.416          100  \n",
       "1                            -178.456          200  \n",
       "2                            -167.960          200  \n",
       "3                            -183.394          200  \n",
       "4                            -165.026          200  \n",
       "...                               ...          ...  \n",
       "9845                         -155.728          100  \n",
       "9846                         -202.436          100  \n",
       "9847                         -179.424          200  \n",
       "9848                         -230.978          200  \n",
       "9849                         -203.862          200  \n",
       "\n",
       "[9850 rows x 14 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train data\n",
    "pre_c = pd.read_csv('./datasets/comparison_feature_data/train_gold_pre.csv')\n",
    "mid_c = pd.read_csv('./datasets/comparison_feature_data/train_gold_mid.csv')\n",
    "late_c = pd.read_csv('./datasets/comparison_feature_data/train_gold_late.csv')\n",
    "\n",
    "pre_a = pd.read_csv('./datasets/all_feature_data/train_gold_pre.csv')\n",
    "mid_a = pd.read_csv('./datasets/all_feature_data/train_gold_mid.csv')\n",
    "late_a = pd.read_csv('./datasets/all_feature_data/train_gold_late.csv')\n",
    "\n",
    "\n",
    "#test data\n",
    "test_pre_c = pd.read_csv('./datasets/comparison_feature_data/test_pre.csv')\n",
    "test_mid_c = pd.read_csv('./datasets/comparison_feature_data/test_mid.csv')\n",
    "test_late_c = pd.read_csv('./datasets/comparison_feature_data/test_late.csv')\n",
    "\n",
    "test_pre_a = pd.read_csv('./datasets/all_feature_data/test_pre.csv')\n",
    "test_mid_a = pd.read_csv('./datasets/all_feature_data/test_mid.csv')\n",
    "test_late_a = pd.read_csv('./datasets/all_feature_data/test_late.csv')\n",
    "pre_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_c = []\n",
    "\n",
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "9845    1\n",
       "9846    1\n",
       "9847    0\n",
       "9848    0\n",
       "9849    0\n",
       "Name: TeamVictory, Length: 9850, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_c['TeamVictory'] = np.where(pre_c['TeamVictory'] == 100, 1,0)\n",
    "test_pre_c['TeamVictory'] = np.where(test_pre_c['TeamVictory'] == 100, 1,0)\n",
    "\n",
    "\n",
    "X_train = pre_c.drop('TeamVictory', axis =1 )\n",
    "y_train = pre_c['TeamVictory']\n",
    "\n",
    "X_test = test_pre_c.drop('TeamVictory', axis =1 )\n",
    "y_test = test_pre_c['TeamVictory']\n",
    "\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.6946 - accuracy: 0.5038\n",
      "Epoch 2/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6790 - accuracy: 0.5830\n",
      "Epoch 3/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6636 - accuracy: 0.6023\n",
      "Epoch 4/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6553 - accuracy: 0.6117\n",
      "Epoch 5/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6524 - accuracy: 0.6134\n",
      "Epoch 6/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6504 - accuracy: 0.6136\n",
      "Epoch 7/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6493 - accuracy: 0.6177\n",
      "Epoch 8/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.6169\n",
      "Epoch 9/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6468 - accuracy: 0.6176\n",
      "Epoch 10/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6454 - accuracy: 0.6183\n",
      "Epoch 11/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6444 - accuracy: 0.6216\n",
      "Epoch 12/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6436 - accuracy: 0.6213\n",
      "Epoch 13/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6428 - accuracy: 0.6217\n",
      "Epoch 14/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6417 - accuracy: 0.6208\n",
      "Epoch 15/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6412 - accuracy: 0.6258\n",
      "Epoch 16/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6401 - accuracy: 0.6200\n",
      "Epoch 17/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6398 - accuracy: 0.6225\n",
      "Epoch 18/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6389 - accuracy: 0.6259\n",
      "Epoch 19/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6383 - accuracy: 0.6245\n",
      "Epoch 20/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6376 - accuracy: 0.6249\n",
      "Epoch 21/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6369 - accuracy: 0.6284\n",
      "Epoch 22/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6364 - accuracy: 0.6261\n",
      "Epoch 23/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6361 - accuracy: 0.6283\n",
      "Epoch 24/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6355 - accuracy: 0.6289\n",
      "Epoch 25/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6343 - accuracy: 0.6279\n",
      "Epoch 26/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6336 - accuracy: 0.6317\n",
      "Epoch 27/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6330 - accuracy: 0.6323\n",
      "Epoch 28/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6325 - accuracy: 0.6333\n",
      "Epoch 29/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6319 - accuracy: 0.6347\n",
      "Epoch 30/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6315 - accuracy: 0.6324\n",
      "Epoch 31/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6301 - accuracy: 0.6347\n",
      "Epoch 32/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6304 - accuracy: 0.6363\n",
      "Epoch 33/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6297 - accuracy: 0.6342\n",
      "Epoch 34/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6291 - accuracy: 0.6348\n",
      "Epoch 35/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6288 - accuracy: 0.6361\n",
      "Epoch 36/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6284 - accuracy: 0.6368\n",
      "Epoch 37/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6282 - accuracy: 0.6370\n",
      "Epoch 38/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6277 - accuracy: 0.6377\n",
      "Epoch 39/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6274 - accuracy: 0.6361\n",
      "Epoch 40/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6270 - accuracy: 0.6359\n",
      "Epoch 41/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6261 - accuracy: 0.6404\n",
      "Epoch 42/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6257 - accuracy: 0.6374\n",
      "Epoch 43/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6259 - accuracy: 0.6392\n",
      "Epoch 44/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6256 - accuracy: 0.6357\n",
      "Epoch 45/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6248 - accuracy: 0.6410\n",
      "Epoch 46/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6241 - accuracy: 0.6387\n",
      "Epoch 47/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6245 - accuracy: 0.6408\n",
      "Epoch 48/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6236 - accuracy: 0.6399\n",
      "Epoch 49/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6229 - accuracy: 0.6407\n",
      "Epoch 50/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.6225 - accuracy: 0.6431\n",
      "17/17 [==============================] - 0s 725us/step\n",
      "[[171 112]\n",
      " [107 132]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5804597701149425"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BEGIN Artificial Neural Network\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Initializing ANN\n",
    "ann = tf.keras.models.Sequential()\n",
    "\n",
    "# adding input and first hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=20, activation='relu'))\n",
    "\n",
    "# adding second hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=10, activation='relu'))\n",
    "\n",
    "# adding third hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=10, activation='relu'))\n",
    "\n",
    "# adding forth hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
    "\n",
    "# adding output layer\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# compiling ANN\n",
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# training ANN on training set\n",
    "ann.fit(X_train, y_train, batch_size = 32, epochs = 50 )\n",
    "\n",
    "\n",
    "y_pred = ann.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.62      0.61       276\n",
      "           1       0.56      0.54      0.55       246\n",
      "\n",
      "    accuracy                           0.58       522\n",
      "   macro avg       0.58      0.58      0.58       522\n",
      "weighted avg       0.58      0.58      0.58       522\n",
      "\n",
      "58.05% Accurate\n"
     ]
    }
   ],
   "source": [
    "#BEGIN Boost\n",
    "#XGBoost\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "XGB = XGBClassifier()\n",
    "XGB.fit(X_train, y_train)\n",
    "y_predict = XGB.predict(X_test)\n",
    "\n",
    "#  prediction Summary\n",
    "print(classification_report(y_predict,y_test))\n",
    "\n",
    "# Accuracy score\n",
    "XGB_SC = accuracy_score(y_predict,y_test)\n",
    "print(f\"{round(XGB_SC*100,2)}% Accurate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65       283\n",
      "           1       0.58      0.58      0.58       239\n",
      "\n",
      "    accuracy                           0.62       522\n",
      "   macro avg       0.61      0.61      0.61       522\n",
      "weighted avg       0.62      0.62      0.62       522\n",
      "\n",
      "61.69% Accurate\n"
     ]
    }
   ],
   "source": [
    "#BEGIN SVM\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "pred_svm = svc.predict(X_test)\n",
    "\n",
    "# prediction Summary\n",
    "print(classification_report(y_test, pred_svm))\n",
    "\n",
    "# Accuracy score\n",
    "svm_SC = accuracy_score(pred_svm, y_test)\n",
    "print(f\"{round(svm_SC*100,2)}% Accurate\")\n",
    "#END SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.71      0.64       283\n",
      "           1       0.54      0.40      0.46       239\n",
      "\n",
      "    accuracy                           0.57       522\n",
      "   macro avg       0.56      0.56      0.55       522\n",
      "weighted avg       0.56      0.57      0.56       522\n",
      "\n",
      "56.9% Accurate\n"
     ]
    }
   ],
   "source": [
    "#BEGIN KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 10)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "pred_knn = knn.predict(X_test)\n",
    "\n",
    "#  prediction Summary\n",
    "print(classification_report(y_test, pred_knn))\n",
    "\n",
    "# Accuracy score\n",
    "knn_SC = accuracy_score(pred_knn, y_test)\n",
    "print(f\"{round(knn_SC*100,2)}% Accurate\")\n",
    "#END KNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45583788f158ccf97e8bfc8f1b755eefbab60f03e39ad2d0d5bdb17f832fcb71"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
